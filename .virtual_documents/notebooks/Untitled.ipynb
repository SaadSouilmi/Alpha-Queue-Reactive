from pathlib import Path
import itertools
from functools import reduce

import polars as pl
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.mixture import GaussianMixture
from tqdm import tqdm


from lobib import DataLoader

sns.set_style("whitegrid")
rng = np.random.default_rng(1337)


def pl_select(condlist: list[pl.Expr], choicelist: list[pl.Expr]) -> pl.Expr:
    return reduce(
        lambda expr, cond_choice: expr.when(cond_choice[0]).then(cond_choice[1]),
        zip(condlist, choicelist),
        pl.when(condlist[0]).then(choicelist[0]),
    )


loader = DataLoader()


dt = dict()

tickers = ["AAL", "AMRX"]
for ticker in tqdm(tickers, position=0, leave=True, colour="green"):
    info = loader.ticker_info(ticker)
    df = loader.load(
        ticker,
        start_date=info["date"].min(),
        end_date=info["date"].max(),
        schema="qr",
        eager=True,
    ).sort(["date", "ts_event"])
    df = df.filter(
        (
            pl.col("event_side")
            .replace({"A": 1, "B": -1})
            .cast(int)
            .mul(pl.col("event_queue_nbr"))
            >= 0
        )
        & pl.col("spread").le(4)
    )
    df = df.with_columns(pl.col("event").replace({"Trd_All": "Trd"}))
    df = df.with_columns(
        pl.when(pl.col("event_queue_nbr").lt(0))
        .then(pl.col("event_queue_nbr").sub(pl.col("best_bid_nbr")).sub(1))
        .otherwise(pl.col("event_queue_nbr").sub(pl.col("best_ask_nbr")).add(1))
        .alias("event_q")
    )
    df = df.filter(pl.col("event_q").abs().le(2) & pl.col("spread").le(4))
    dt_ = df.select(pl.col("ts_event").diff().over("date").cast(int).alias("dt")).filter(pl.col("dt").gt(0))
    dt_ = dt_.with_columns(pl.col("dt").log10().alias("dt_log"))
    dt[ticker] = dt_["dt_log"]


modes = {}
half_widths = {}

for ticker in tickers:
  data = dt[ticker].to_numpy()

  n_bins = min(500, int(np.sqrt(len(data))))
  counts, bins = np.histogram(data, bins=n_bins, density=True)
  bin_centers = (bins[:-1] + bins[1:]) / 2

  # Find mode
  mode_idx = np.argmax(counts)
  mode_val = bin_centers[mode_idx]
  modes[ticker] = mode_val

  # Find 50% threshold bounds
  mode_density = counts[mode_idx]
  threshold = mode_density * 0.5

  # Left bound
  left_idx = np.where(counts[:mode_idx] < threshold)[0]
  left_bound = bin_centers[left_idx[-1]] if len(left_idx) > 0 else bin_centers[0]

  # Right bound
  right_idx = np.where(counts[mode_idx:] < threshold)[0]
  right_bound = bin_centers[mode_idx + right_idx[0]] if len(right_idx) > 0 else bin_centers[-1]

  half_widths[ticker] = (left_bound, right_bound)



fig, axes = plt.subplots(1, len(tickers), figsize=(6 * len(tickers), 4), sharey=True)

for ax, ticker in zip(axes, tickers):
  data = dt[ticker].to_numpy()

  ax.hist(data, bins=100, density=True, alpha=0.5, color='steelblue', edgecolor='black', linewidth=0.3)
  ax.axvline(modes[ticker], color='red', linestyle='--', linewidth=1.5, label=f'Mode: {modes[ticker]:.2f}')

  ax.legend(fontsize=8)
  ax.set_xlabel("log₁₀(dt) [ns]")
  ax.set_ylabel("Density")
  ax.set_title(ticker)
  ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()



fig, axes = plt.subplots(1, len(tickers), figsize=(6 * len(tickers), 4), sharey=True)

for ax, ticker in zip(axes, tickers):
  data = dt[ticker].to_numpy()
  data_zoomed = data[data < 5.5]

  left_bound, right_bound = half_widths[ticker]
  mode_val = modes[ticker]

  # Get threshold density value
  counts, bins = np.histogram(data_zoomed, bins=100, density=True)
  bin_centers = (bins[:-1] + bins[1:]) / 2
  mode_idx = np.argmax(counts)
  threshold = counts[mode_idx] * 0.5

  ax.hist(data_zoomed, bins=100, density=True, alpha=0.5, color='steelblue', edgecolor='black', linewidth=0.3)
  ax.axvspan(left_bound, right_bound, alpha=0.3, color='coral', label=f'Peak region [{left_bound:.2f}, {right_bound:.2f}]')
  ax.axvline(mode_val, color='red', linestyle='--', linewidth=1.5, label=f'Peak at {mode_val:.2f}')
  ax.axhline(threshold, color='gray', linestyle=':', linewidth=2, label=f'50% Peak Density')

  ax.legend(fontsize=8)
  ax.set_xlabel("log₁₀(dt) [ns]")
  ax.set_ylabel("Density")
  ax.set_title(ticker)
  ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()



info = loader.ticker_info("AAL")
df = loader.load(
    "AAL",
    start_date=info["date"].min(),
    end_date=info["date"].max(),
    schema="qr",
    eager=True,
).sort(["date", "ts_event"])
df = df.filter(
    (
        pl.col("event_side")
        .replace({"A": 1, "B": -1})
        .cast(int)
        .mul(pl.col("event_queue_nbr"))
        >= 0
    )
    & pl.col("spread").le(4)
)
df = df.with_columns(pl.col("event").replace({"Trd_All": "Trd"}))
df = df.with_columns(
    pl.when(pl.col("event_queue_nbr").lt(0))
    .then(pl.col("event_queue_nbr").sub(pl.col("best_bid_nbr")).sub(1))
    .otherwise(pl.col("event_queue_nbr").sub(pl.col("best_ask_nbr")).add(1))
    .alias("event_q")
)
condlist = [pl.col("best_bid_nbr").eq(-i) for i in range(1, 11)]
choicelist = [pl.col(f"Q_{-i}") for i in range(1, 11)]
best_bid = pl_select(condlist, choicelist).alias("best_bid").truediv(500).ceil()

condlist = [pl.col("best_ask_nbr").eq(i) for i in range(1, 11)]
choicelist = [pl.col(f"Q_{i}") for i in range(1, 11)]
best_ask = pl_select(condlist, choicelist).alias("best_ask").truediv(500).ceil()
imb = ((best_bid - best_ask) / (best_bid + best_ask)).alias("imb")

df = df.with_columns(imb)

bins = np.arange(11, step=1) / 10
condlist = [
    *[
        pl.col("imb").ge(left) & pl.col("imb").lt(right)
        for left, right in zip(-bins[1:][::-1], -bins[:-1][::-1])
    ],
    pl.col("imb").eq(0),
    *[
        pl.col("imb").gt(left) & pl.col("imb").le(right)
        for left, right in zip(bins[:-1], bins[1:])
    ],
]
choicelist = [*(-bins[1:][::-1]), 0, *bins[1:]]
df = df.with_columns(pl_select(condlist, choicelist).alias("imb_bin"))
df = df.filter(pl.col("event_q").abs().le(2) & pl.col("spread").le(4))
df = df.with_columns(pl.when(pl.col("spread").ge(2)).then(2).otherwise(pl.col("spread")).alias("spread"))
dt = df.select(pl.col("ts_event").diff().over("date").cast(int).alias("dt"), "imb_bin", "spread").filter(pl.col("dt").gt(0))
dt = dt.with_columns(pl.col("dt").log10().alias("dt_log"))


dt_filtered = dt.filter(pl.col("dt_log").gt(4.4))

# Get unique imbalance bins and spreads
imb_bins = sorted(dt_filtered["imb_bin"].unique().to_list())
spreads = sorted(dt_filtered["spread"].unique().to_list())

# Create figure with 21x2=42 subplots (7 rows x 6 cols, 3 per spread)
fig, axes = plt.subplots(7, 6, figsize=(20, 20))

# Fit GMM for each (imb_bin, spread) pair
gmm_params = []

for i, imb_bin in enumerate(imb_bins):
  for j, spread in enumerate(spreads):
      # Column: spread=1 uses cols 0,1,2; spread=2 uses cols 3,4,5
      col = (i % 3) + (j * 3)
      row = i // 3
      ax = axes[row, col]

      # Get data for this (imb_bin, spread) pair
      data = dt_filtered.filter(
          (pl.col("imb_bin").eq(imb_bin)) & (pl.col("spread").eq(spread))
      )["dt_log"].to_numpy()

      if len(data) < 10:
          ax.set_title(f"imb={imb_bin:.1f}, s={spread} (n={len(data)})", fontsize=8)
          ax.text(0.5, 0.5, "Insufficient data", ha="center", va="center", transform=ax.transAxes)
          continue

      log_dt = data.reshape(-1, 1)

      # Fit 3-component Gaussian mixture
      gmm = GaussianMixture(n_components=3, random_state=42).fit(log_dt)

      # Extract parameters
      means = gmm.means_.flatten()
      stds = np.sqrt(gmm.covariances_.flatten())
      weights = gmm.weights_

      # Store params (spread as 0 or 1 for C++ indexing)
      gmm_params.append({
          "imb_bin": imb_bin,
          "spread": spread - 1,  # 0 for spread=1, 1 for spread>=2
          "w1": weights[0], "mu1": means[0], "sigma1": stds[0],
          "w2": weights[1], "mu2": means[1], "sigma2": stds[1],
          "w3": weights[2], "mu3": means[2], "sigma3": stds[2],
          "n": len(data)
      })

      # Plot
      x = np.linspace(log_dt.min() - 0.5, log_dt.max() + 0.5, 200)
      pdf1 = weights[0] * stats.norm.pdf(x, means[0], stds[0])
      pdf2 = weights[1] * stats.norm.pdf(x, means[1], stds[1])
      pdf3 = weights[2] * stats.norm.pdf(x, means[2], stds[2])
      pdf_mix = pdf1 + pdf2 + pdf3

      ax.hist(log_dt, bins=50, density=True, alpha=0.5, color="gray")
      ax.plot(x, pdf1, "--", lw=1, label=f"w={weights[0]:.2f}")
      ax.plot(x, pdf2, "--", lw=1, label=f"w={weights[1]:.2f}")
      ax.plot(x, pdf3, "--", lw=1, label=f"w={weights[2]:.2f}")
      ax.plot(x, pdf_mix, "r-", lw=1.5)
      ax.set_title(f"imb={imb_bin:.1f}, s={spread} (n={len(data):,})", fontsize=8)
      ax.legend(fontsize=6, loc="upper right")
      ax.set_xlabel("log10(dt)", fontsize=7)
      ax.set_ylabel("Density", fontsize=7)
      ax.tick_params(labelsize=6)

plt.suptitle("Gaussian Mixture (3 components) for log10(dt), by (imb_bin, spread)", fontsize=14)
plt.tight_layout()
plt.subplots_adjust(top=0.95)
plt.show()

params_df = pl.DataFrame(gmm_params)


# params_df.write_csv("../data/AAL2/delta_t_mixtures_floored.csv")


fig, ax = plt.subplots(figsize=(8, 5))

left_tail = dt.filter(pl.col("dt_log").lt(4.4))["dt_log"]
# Shift data for fitting (both require x > 0)
left_tail_shifted = left_tail - left_tail.min() + 0.01

# Fit Gamma and Weibull
a_gamma, _, scale_gamma = stats.gamma.fit(left_tail_shifted, floc=0)
c_weibull, _, scale_weibull = stats.weibull_min.fit(left_tail_shifted, floc=0)

# Plot: log10 space
ax.hist(left_tail, bins=80, alpha=0.6, color='steelblue', edgecolor='black', linewidth=0.5, density=True)
x_log = np.linspace(left_tail.min(), left_tail.max(), 200)
x_shifted = x_log - left_tail.min() + 0.01
ax.plot(x_log, stats.gamma.pdf(x_shifted, a_gamma, loc=0, scale=scale_gamma), 'r-', lw=2,
  label=f'Gamma(k={a_gamma:.2f}, θ={scale_gamma:.2f})')
ax.plot(x_log, stats.weibull_min.pdf(x_shifted, c_weibull, loc=0, scale=scale_weibull), 'g-', lw=2,
  label=f'Weibull(k={c_weibull:.2f}, λ={scale_weibull:.2f})')
ax.axvline(4.39, color='gray', linestyle='--', lw=1.5, label='max_log10=4.39')
ax.set_xlabel("log10(dt)")
ax.set_ylabel("Density")
ax.set_title(f"{ticker} — Left tail — n={len(left_tail):,}")
ax.legend()

plt.tight_layout()
plt.show()

# Log-likelihood comparison
ll_gamma = np.sum(stats.gamma.logpdf(left_tail_shifted, a_gamma, loc=0, scale=scale_gamma))
ll_weibull = np.sum(stats.weibull_min.logpdf(left_tail_shifted, c_weibull, loc=0, scale=scale_weibull))

print(f"Log-likelihood: Gamma={ll_gamma:.1f}, Weibull={ll_weibull:.1f}")
print(f"\nGamma:   k={a_gamma:.4f}, θ={scale_gamma:.4f}")
print(f"Weibull: k={c_weibull:.4f}, λ={scale_weibull:.4f}")
print(f"Shift:   {left_tail.min():.4f}")



shift_val = left_tail.min()

pl.DataFrame({
  "k": [a_gamma],
  "scale": [scale_gamma],
  "shift": [shift_val],
  "max_log10": [4.4]
}).write_csv("../data/AAL2/gamma_distrib.csv")

pl.DataFrame({
  "k": [c_weibull],
  "scale": [scale_weibull],
  "shift": [shift_val],
  "max_log10": [4.4]
}).write_csv("../data/AAL2/weibull_distrib.csv")



k_gamma = a_gamma
scale_gamma = scale_gamma
k_weibull = c_weibull
scale_weibull = scale_weibull
shift_val = left_tail.min()
max_log10 = 4.4

n_samples = 100000

# Sample Gamma
samples_gamma = []
while len(samples_gamma) < n_samples:
  x = stats.gamma.rvs(k_gamma, scale=scale_gamma, size=n_samples)
  log10_dt = x + shift_val
  valid = log10_dt[log10_dt <= max_log10]
  samples_gamma.extend(valid)
samples_gamma = np.array(samples_gamma[:n_samples])

# Sample Weibull
samples_weibull = []
while len(samples_weibull) < n_samples:
  x = stats.weibull_min.rvs(k_weibull, scale=scale_weibull, size=n_samples)
  log10_dt = x + shift_val
  valid = log10_dt[log10_dt <= max_log10]
  samples_weibull.extend(valid)
samples_weibull = np.array(samples_weibull[:n_samples])

# Plot
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Log10 space
ax = axes[0]
ax.hist(samples_gamma, bins=80, alpha=0.5, color='red', density=True, label='Gamma samples')
ax.hist(samples_weibull, bins=80, alpha=0.5, color='green', density=True, label='Weibull samples')
ax.axvline(max_log10, color='gray', linestyle='--', lw=1.5, label=f'max_log10={max_log10}')
ax.set_xlabel("log₁₀(dt)")
ax.set_ylabel("Density")
ax.set_title("Sampled inter-racer delays (log scale)")
ax.legend()

# Nanoseconds
ax = axes[1]
ax.hist(10**samples_gamma, bins=80, alpha=0.5, color='red', density=True, label='Gamma samples')
ax.hist(10**samples_weibull, bins=80, alpha=0.5, color='green', density=True, label='Weibull samples')
ax.axvline(10**max_log10, color='gray', linestyle='--', lw=1.5, label=f'max={10**max_log10:.0f}ns')
ax.set_xlabel("dt (ns)")
ax.set_ylabel("Density")
ax.set_title("Sampled inter-racer delays (ns scale)")
ax.legend()

plt.tight_layout()
plt.show()

print(f"Gamma:   mean={samples_gamma.mean():.2f}, std={samples_gamma.std():.2f} (log10)")
print(f"Weibull: mean={samples_weibull.mean():.2f}, std={samples_weibull.std():.2f} (log10)")
print(f"\nGamma:   mean={10**samples_gamma.mean():.0f}ns")
print(f"Weibull: mean={10**samples_weibull.mean():.0f}ns")







