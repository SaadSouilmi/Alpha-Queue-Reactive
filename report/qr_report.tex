\documentclass[11pt,a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[margin=2.5cm]{geometry}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}

\title{Queue Reactive}
\date{}

\begin{document}

\maketitle

%==============================================================================
\section{Queue Reactive Model}
%==============================================================================

\subsection{Model Definition}

At any time $t$, the order book $\text{LOB}(t)$ is projected onto a state $f(\text{LOB}) = (\text{Imb}, n)$ where:
\begin{equation}
    \text{Imb} = \frac{Q^B - Q^A}{Q^B + Q^A}
\end{equation}
and $n$ is the bid-ask spread in ticks. The order book is comprised of different levels: $1$ and $-1$ are respectively the best ask and bid regardless of the spread between the two, and the levels $\pm l$ for $l \in \{2, \ldots\}$ are $l-1$ ticks away from the best ask/bid.

The possible events are $L$: limit orders, $C$: cancellations, $T$: market orders and $+$: add in spread orders. Each event $e$ is a combination of an event type, a side $B$:bid/$A$:ask and a level (or an available queue for add in spread).

At time $t$ when the current state of the order book is $(\text{Imb}, n)$ the next event is distributed according to:
\begin{equation}
    \Delta t = \min_{e \in \mathcal{E}} \Delta t^e, \quad e^* = \arg\min_{e \in \mathcal{E}} \Delta t^e \quad \text{where } \Delta t^e \sim \text{Exp}(\lambda^e(\text{Imb}, n))
\end{equation}
where $\mathcal{E}$ is the set of all possible events. Or alternatively if we consider:
\begin{equation}
    \Lambda(\text{Imb}, n) = \sum_{e \in \mathcal{E}} \lambda^e(\text{Imb}, n) \quad \text{and} \quad q^e = \frac{\lambda^e(\text{Imb}, n)}{\Lambda(\text{Imb}, n)}
\end{equation}
Then:
\begin{equation}
    \Delta t \sim \text{Exp}(\Lambda(\text{Imb}, n)) \quad \text{and} \quad e^* \sim \sum_{e \in \mathcal{E}} q^e \delta_e
\end{equation}

\subsection{Estimation}

Let $t_k$ be the $k$-th timestamp, and $\Delta t_k = t_k - t_{k-1}$. Let $\mathcal{T} = \{(t_k, e_k, \text{Imb}_k, n_k)\}_{k \in \mathbb{N}}$ be our dataset.

Let $\mathcal{K}^e(\text{Imb}, n)$ be the set of indices $k$ such that the event $e$ occurred at time $t_k$ and the previous state was $(\text{Imb}, n)$:
\begin{equation}
    \mathcal{K}^e(\text{Imb}, n) = \{k : e_k = e, f(\text{LOB}(t_{k-1})) = (\text{Imb}, n)\} \quad \text{and} \quad \mathcal{K}(\text{Imb}, n) = \bigcup_{e \in \mathcal{E}} \mathcal{K}^e(\text{Imb}, n)
\end{equation}

Since $\Delta t_k \mid k \in \mathcal{K}(\text{Imb}, n) \sim \text{Exp}(\Lambda(\text{Imb}, n))$, we have:
\begin{equation}
    \hat{\Lambda}(\text{Imb}, n) = \left( \frac{1}{\#\mathcal{K}(\text{Imb}, n)} \sum_{e \in \mathcal{E}} \sum_{k \in \mathcal{K}^e(\text{Imb}, n)} \Delta t_k^e \right)^{-1} \quad \text{and} \quad \hat{q}^e = \frac{\#\mathcal{K}^e(\text{Imb}, n)}{\#\mathcal{K}(\text{Imb}, n)}
\end{equation}

\subsection{Adding the Total Level Dimension}

The base model projects the LOB onto $(\text{Imb}, n)$, but this loses information about the \emph{absolute size} of the queues. Consider two states:
\begin{itemize}
    \item $Q^B = 1, Q^A = 1 \Rightarrow \text{Imb} = 0$
    \item $Q^B = 50, Q^A = 50 \Rightarrow \text{Imb} = 0$
\end{itemize}
Both have zero imbalance, but the dynamics are completely different. A thin book (1-1) is fragile: a single cancellation or market order depletes an entire queue. A thick book (50-50) is stable and can absorb many events before a price move.

To capture this, I extend the state to include the total level:
\begin{equation}
    f(\text{LOB}) = (\text{Imb}, n, \ell) \quad \text{where} \quad \ell = Q^B + Q^A
\end{equation}

In practice, $\ell$ is bucketed into quantiles (e.g., terciles or quartiles) estimated from data. The event probabilities then become $q^e(\text{Imb}, n, \ell)$, allowing the model to behave differently for thin vs thick books at the same imbalance.

The estimation is analogous to the 2D case:
\begin{equation}
    \mathcal{K}^e(\text{Imb}, n, \ell) = \{k : e_k = e, f(\text{LOB}(t_{k-1})) = (\text{Imb}, n, \ell)\}
\end{equation}
\begin{equation}
    \hat{q}^e(\text{Imb}, n, \ell) = \frac{\#\mathcal{K}^e(\text{Imb}, n, \ell)}{\#\mathcal{K}(\text{Imb}, n, \ell)}
\end{equation}

\subsection{Practical Considerations}

The imbalance is separated into 11 bins of equal width, including 0.

Since I mainly care about large tick stocks and to avoid estimating too many statistics, I only consider up to level 2 (the best bid/ask and a tick beyond), and only for a spread of 1 tick ($n = 1$). If the spread is above 1 tick the only possible event is an add in spread.

I also added random volumes for the different events, bucketed according to the median event size per level.

\paragraph{Add in Spread.} When the spread is equal to 2 ticks, there is only one available queue for an add in spread, making estimation easy since I only estimate the side of the add in spread per imbalance bucket. When sampling, if the spread goes beyond 2, I draw a side according to statistics for spread equal to 2 and draw a queue at random from available or empty queues.

\paragraph{Random Volumes.} Volumes are bucketed according to median event size per level, i.e., we take the smallest integer $\geq$ volumes divided by median event size. For each imbalance bin, event type, event side and event level, I estimate the empirical distribution of volumes to sample from.

For add in spread event, I consider the cumulative volume of all orders in the added level as long as there are no events in other queues.

\paragraph{Data.} I work with Databento MBP10 data (L2), with a separate dataframe for each stock/day. I cut 30 minutes from the beginning and end of each trading day to avoid the opening and close.

%==============================================================================
\section{First Results}
%==============================================================================

Running the QR model with exponential inter-event times produces event probabilities that match the data reasonably well. However, the $\Delta t$ distribution is completely off.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/dt_distribution_emp_vs_qr_exp.pdf}
    \caption{Distribution of $\Delta t$: empirical vs QR with exponential timing. The QR model fails to capture the shape of the inter-event time distribution.}
\end{figure}

To fix this, we can either sample directly from the empirical distribution of $\Delta t$ (conditioned on imbalance bin and spread), or fit a parametric model. I chose to fit a Gaussian Mixture Model (GMM) over $\log(\Delta t)$ for each $(\text{Imb}, n)$ state. Working in log-space ensures $\Delta t > 0$ and captures the heavy-tailed nature of the distribution.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/dt_distribution_emp_vs_qr_gmm.pdf}
    \caption{Distribution of $\Delta t$: empirical vs QR with GMM timing. The GMM captures the shape much better.}
\end{figure}

QR captures average statistics well.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/event_type_distribution_emp_vs_qr.pdf}
    \caption{Event type distribution: empirical vs QR.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/imbalance_distribution_emp_vs_qr.pdf}
    \caption{Imbalance distribution: empirical vs QR.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/spread_distribution_before_trades_emp_vs_qr.pdf}
    \caption{Spread distribution before trades: empirical vs QR.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/queue_size_distribution_emp_vs_qr.pdf}
    \caption{Queue size distribution: empirical vs QR.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/nb_daily_events_distribution_emp_vs_qr.pdf}
    \caption{Number of daily events: empirical vs QR.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/hourly_traded_volume_distribution_emp_vs_qr.pdf}
    \caption{Hourly traded volume distribution: empirical vs QR.}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/5min_vol_daily_distribution_emp_vs_qr.pdf}
    \caption{5-minute volume distribution: empirical vs QR.}
\end{figure}

\paragraph{Daily Volatility.} Let $p_t$ be the last traded price in each 5-minute bin. The daily volatility is:
\begin{equation}
    \sigma_{\text{day}} = \sqrt{\frac{1}{H - 1} \sum_{t=1}^{T} (p_{t+1} - p_t)^2}
\end{equation}
where $H = 5.5$ is the number of trading hours (6.5 hours minus 30 minutes from open and close).

\paragraph{Eta ($\eta$).} In trade space, let $m_k$ be the mid price before the $k$-th trade. Define:
\begin{itemize}
    \item $N_{\text{cont}}$ = number of continuations: consecutive mid price changes with the same sign
    \item $N_{\text{alt}}$ = number of alternations: consecutive mid price changes with opposite signs
\end{itemize}
Then:
\begin{equation}
    \eta = \frac{N_{\text{cont}}}{2 N_{\text{alt}}}
\end{equation}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/eta_distribution_emp_vs_qr.pdf}
    \caption{$\eta$ distribution: empirical vs QR.}
\end{figure}

%==============================================================================
\section{Market Impact}
%==============================================================================

When a large metaorder hits the market, it moves the price in its direction. Buy orders push the price up, sell orders push it down. However, this impact should decay over time as the market absorbs the information.

In the standard QR model, the price on average doesn't move---there is no persistent drift. The model is symmetric: bid and ask trades are equally likely given the same imbalance. This means we cannot capture the transient price impact of a large order flow.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/no_impact_metaorder.pdf}
    \caption{Metaorder price impact without the EMA model. The price moves in the direction of the metaorder but does not revert.}
\end{figure}

\subsection{EMA Impact Model}

To introduce decaying market impact, I track an exponential moving average of trade signs:
\begin{equation}
    \phi_t = \alpha \cdot \xi_{\text{last}} + (1 - \alpha) \cdot \phi_{t-1}
\end{equation}
where $\xi = +1$ for ask (buy) trades and $\xi = -1$ for bid (sell) trades, and $\alpha \in (0, 1)$ is the decay parameter.

The QR trade probabilities are then biased according to $\phi_t$:
\begin{equation}
    P(\text{bid trade}) \propto P_0(\text{bid trade}) \cdot e^{m \phi_t}, \quad
    P(\text{ask trade}) \propto P_0(\text{ask trade}) \cdot e^{-m \phi_t}
\end{equation}
where $m > 0$ is a scaling coefficient.

When $\phi_t > 0$ (recent buy pressure), ask trades become less likely and bid trades more likely, creating mean reversion. This causes the price impact to decay over time as the market ``pushes back'' against the original order flow.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/ema_impact_metaorder.pdf}
    \caption{Metaorder price impact with the EMA model. The metaorder is 5\% of average hourly volume executed over 5 minutes. Simulation: 100k paths over 60 minutes. The price reverts after the metaorder completes.}
\end{figure}

%==============================================================================
\section{Introducing Signals}
%==============================================================================

We introduce an exogenous signal $\alpha_t$ that biases trade probabilities. The signal represents private information about future price direction: $\alpha > 0$ predicts price increases, $\alpha < 0$ predicts decreases.

The combined biasing mechanism is:
\begin{equation}
    P(\text{bid}) \propto P_0(\text{bid}) \cdot e^{\phi_t - \alpha_t}, \quad
    P(\text{ask}) \propto P_0(\text{ask}) \cdot e^{-\phi_t + \alpha_t}
\end{equation}
where $\phi_t$ is the market impact term and $\alpha_t$ is the signal. When $\alpha > 0$, ask trades (buys) become more likely, pushing the price up toward the signal's prediction.

Signal predictivity is measured by:
\begin{equation}
    \mathbb{E}[\alpha_t \cdot (P_{t+\Delta t} - P_t)]
\end{equation}

The signal follows an Ornstein-Uhlenbeck process:
\begin{equation}
    d\alpha_t = -\kappa \alpha_t \, dt + \sigma \, dW_t
\end{equation}
with $\kappa = 0.5$ min$^{-1}$ (half-life $\approx 1.4$ min), so the signal fades after about 5 minutes.

%==============================================================================
\section{Round-Trip Time}
%==============================================================================

Plotting the distribution of inter-event times $\Delta t$ in $\log_{10}$ space reveals a consistent mode around $\log_{10}(\Delta t) \approx 4.47$, corresponding to approximately \textbf{29 microseconds}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/dt_hist.png}
    \caption{Distribution of inter-event times. The mode at $\sim$29$\mu$s is consistent across stocks.}
\end{figure}

Zooming into the peak region, the interval where density drops to 50\% of the maximum is tight: $[4.39, 4.55]$ in $\log_{10}$ space, or roughly $[24\mu s, 35\mu s]$.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{../figures/dt_hist_zoomed.png}
    \caption{Peak region with 50\% density bounds.}
\end{figure}

This represents the \textbf{round-trip time} $\delta$: the time for an order to reach the exchange, be processed by the matching engine, and propagate back to the public data feed. Fitting a Gaussian to the peak region yields:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{../figures/peak_fit.png}
    \caption{Gaussian fit to the round-trip time peak.}
\end{figure}

Queue-reactive events are reactions to the order book state. An agent observes the book, decides to act, and sends an order. Thus inter-event times should be at least $\delta$ plus some reaction time. This justifies fitting the GMM only to the peak region and beyond---excluding the fast left tail.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../figures/mixture_fit.png}
    \caption{GMM fit to QR inter-event times by (imbalance, spread).}
\end{figure}

%==============================================================================
\section{Race Mechanism}
%==============================================================================

The fast left tail of the $\Delta t$ distribution represents \textbf{race events}---bursts of aggressive orders in the direction of the signal $\alpha_t$. When $\alpha > 0$, racers target the ask side; when $\alpha < 0$, they target the bid side.

\subsection{Race Triggering}

Races are triggered with probability depending on $|\alpha|$:
\begin{equation}
    P(\text{race}|\alpha) = \begin{cases}
        0 & \text{if } |\alpha| < 0.8 \\
        \frac{1}{1 + e^{-8(|\alpha| - 0.7)}} & \text{otherwise}
    \end{cases}
\end{equation}

The number of racers follows a geometric distribution with mean scaling with $|\alpha|$:
\begin{equation}
    \mathbb{E}[N|\alpha] = 4 + 2.5 \cdot (|\alpha| - 0.7)
\end{equation}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../figures/race_proba_nb.png}
    \caption{Race probability and expected number of racers vs $\alpha$.}
\end{figure}

\subsection{Race Composition}

Race orders are composed of (base probabilities):
\begin{itemize}
    \item \textbf{45\% trades}: aggressive orders consuming liquidity
    \item \textbf{30\% limits}: limit orders on the same side as $\alpha$
    \item \textbf{25\% cancels}: defensive orders pulling liquidity before adverse selection
\end{itemize}

As $|\alpha|$ increases beyond the threshold, limit probability decays and the freed probability redistributes: 60\% to trades, 40\% to cancels.

\subsection{Inter-Arrival Times}

The timing is modeled as:
\begin{itemize}
    \item The first racer arrives at time $t_0 + \delta$ (round-trip delay)
    \item Subsequent racers arrive with inter-arrival delays $\gamma_i$ drawn from the left tail
    \item The $i$-th racer arrives at: $t_0 + \delta + \sum_{j=1}^{i-1} \gamma_j$
\end{itemize}

We fit both Gamma and Weibull distributions to the left tail ($\log_{10}(\Delta t) < 4.39$):

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../figures/tail_fit.png}
    \caption{Gamma and Weibull fits to the left tail.}
\end{figure}

\subsection{Race Consumption}

There is a problem with triggering races whenever $|\alpha| > 0.8$: a race completes in microseconds, but $\alpha$ decays over minutes. After a race ends, $\alpha$ is still above threshold, so the next event triggers another race. Even imposing a QR event between consecutive races results in excessive volume---nearly all activity becomes races.

The solution is to have each race \textbf{consume} a fraction $\theta$ of the signal:
\begin{equation}
    \alpha \leftarrow (1 - \theta) \cdot \alpha
\end{equation}
This makes intuitive sense: races represent informed traders acting on the signal, and their activity partially incorporates the information into prices.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/alpha_decay.pdf}
    \caption{Alpha decay with race consumption ($\theta > 0$).}
\end{figure}

\end{document}
